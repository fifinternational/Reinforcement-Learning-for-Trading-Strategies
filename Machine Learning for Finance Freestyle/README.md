# Machine Learning for Finance Freestyle

## Overview
In this specialization you've learned a number of machine learning algorithms and tools. This labs gives you the opportunity to apply what you have learned to SP500 daily data. There's no prescription. We give you the data and encourage you to be creative.

### Objectives
In this lab, you will:

Pull daily SP500 data using BigQuery
Train a machine learning model to predict directional movement of stocks
Compare your model to several benchmarks, including AutoML Tables
Once you're ready, scroll down and follow the steps below to get your lab environment set up.

## Task 1. Launch AI Platform Notebooks
To launch AI Platform Notebooks:

1. Click on the Navigation Menu. Navigate to AI Platform, then to Notebooks.

2. On the Notebook instances page, click New Notebook.

3. Select TensorFlow Enterprise and choose the latest version of TensorFlow Enterprise 2.6 (with LTS) > Without GPUs.

4. In the pop-up, confirm the name of the deep learning VM, and then move to the bottom of the window and click Create.

The new VM will take 2-3 minutes to start.

5. Click Open JupyterLab. A JupyterLab window opens in a new tab.

## Task 2. Clone code
To clone the relevant notebook into your JupyterLab instance:

1. In JupyterLab, click the Terminal icon to open a new terminal.
The Launcher page, which includes a highlighted Terminal tile.

2. At the command-line prompt, type in the following command and press Enter:
```
git clone https://github.com/GoogleCloudPlatform/training-data-analyst.git
```
3. Confirm that you have cloned the repository by double clicking on the training-data-analyst directory and ensuring you can see its contents.

## Task 3. Run through the notebook
1. From the left-hand menu, select training-data-analyst > courses > ai-for-finance > practice > freestyle.ipynb. This will open a new tab.

2. Ensure you're using the Python 3 kernel by selecting Python 3 from the upper right corner of the notebook.

3. Read through the notebook's contents and run all code blocks with Shift + Enter.

4. Return here after you have completed the instructions in the notebook.

5. You can try building a model using AutoML Tables to serve as a benchmark. AutoML will take only a few minutes to get going and around an hour to train. While training, you can work on developing your own model.

### Build a model using AutoML tables
1. In the GCP console, select Tables > Datasets under the ARTIFICIAL INTELLIGENCE section.

2. Click Enable API to turn on the Cloud AutoML API if it is not already enabled.

3. Click NEW DATASET. 

4. Give your dataset a name like SP500 and then click on CREATE DATASET. The completed dataset name and region fields withint he Create new dataset page, along with a Create dataset button.

5. In the interface select the following options:

- Import data from BigQuery
- BigQuery Project ID = cloud-training-prod-bucket
- BigQuery Dataset ID = ml4f
- BigQuery Table or View ID = percent_change_sp500 The Import tabbed page, which includes the aforementioned details.
6. Click on Import. You may have to wait around 10 minutes. The Import tabbed page, with the "Your data is being imported" status running.

7. After the data is imported, the TRAIN tab should display this: The Train tabbed page, with several rows of formatting options as well as a summary of the data.

8. Select direction for Target column.

9. Click on TRAIN MODEL.

10. Input 1 node hour for the training budget.

11. For Input feature selection click on only the following features:

- symbol

- close_MIN_prior_5_days

- close_MIN_prior_20_days

- close_MIN_prior_260_days

- close_MAX_prior_5_days

- close_MAX_prior_20_days

- close_MAX_prior_260_days

- close_AVG_prior_5_days

- close_AVG_prior_20_days

- close_AVG_prior_260_days

- close_STDDEV_prior_5_days

- close_STDDEV_prior_20_days

- close_STDDEV_prior_260_days

12. Click TRAIN MODEL. The model will take around an hour to train. The Models tabbed page, with a running status.

13. Inspect the evaluation metrics generated by AutoML Tables.

Is this model any good? Can you build a better model? The sp500 model, with the Evaluate tabbed page displayed, which includes 3 graphs and a confusion matrix.

